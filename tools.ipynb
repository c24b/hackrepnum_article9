{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des libraries nécessaires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import re\n",
    "from pandas.io.json import json_normalize\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_json(jsonfile):\n",
    "    with open(jsonfile, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def read_csv(csvfile, sep=\",\"):\n",
    "    return pd.read_csv(csvfile, sep=sep)\n",
    "    \n",
    "def write_json(data, jsonfile):\n",
    "    with open(jsonfile, \"w\") as f:\n",
    "        data = json.dumps(data, indent=4)\n",
    "        f.write(unicode(data))\n",
    "    return\n",
    "    \n",
    "def write_csv(data, csvfile, delimiter=\"\\t\"):\n",
    "    '''\n",
    "    Write in tabular mode \n",
    "    from a dict or a nested dict\n",
    "    '''\n",
    "    if isinstance(data, list):\n",
    "        header = data[0]\n",
    "        if isinstance(header, list):\n",
    "            #here means it's a simple matrix\n",
    "            with open(csvfile, \"w\") as f:\n",
    "                csvwriter = csv.writer(f, delimiter=delimiter)\n",
    "                for row in data:\n",
    "                    csvwriter.writerow(row)\n",
    "                \n",
    "        elif isinstance(header, dict):\n",
    "            #here means it's a simple dict:\n",
    "            #so mapp the 1st set of keys as column_name\n",
    "            with open(csvfile, \"w\") as f:\n",
    "                csvwriter = csv.writer(f, delimiter=delimiter)\n",
    "                csvwriter.writerow(header.keys())\n",
    "                for row in data:\n",
    "                    csvwriter.writerow(row.values())\n",
    "                    \n",
    "            \n",
    "    elif isinstance(data, dict):\n",
    "        #here means it's a simple dict:\n",
    "        #so mapp the 1st set of keys as column_name\n",
    "        with open(csvfile, \"w\") as f:\n",
    "            csvwriter = csv.writer(f, delimiter=delimiter)\n",
    "            csvwriter.writerow(data.keys())\n",
    "            csvwriter.writerow(data.values())\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Invalid format of type %s. Data can't be written to a csv file\") %type(data)\n",
    "    return\n",
    "  \n",
    "def normalize(data):\n",
    "    '''\n",
    "    les données en entrées sont une liste d'enregistrement en dictionnaires\n",
    "    chaque dictionnaire a des clés valeurs\n",
    "    ajoute les clés valeurs manquantes à certains dictionnaires\n",
    "    en \"aplatissant\" les nours du dictionnaires\n",
    "    pour permettre la vision tabulaire\n",
    "    '''\n",
    "    items_keys = set()\n",
    "    #building the reference of columns\n",
    "    for item in data:\n",
    "        new_item = flatten(item)\n",
    "        items_keys.update(new_item.keys())\n",
    "    items_keys = [str(n).encode(\"utf-8\") for n in list(set(items_keys))]\n",
    "    #building new default dict\n",
    "    #with all the keys awaited, values are set to None in this case\n",
    "    new_list =[]\n",
    "    for item in data:\n",
    "        item_ref = collections.defaultdict.fromkeys(items_keys, u'')\n",
    "        for k, v in item.items():\n",
    "            try:\n",
    "                item_ref[k] = v.encode(\"utf-8\")\n",
    "            except AttributeError:\n",
    "                item_ref[k] = str(v).encode(\"utf-8\")\n",
    "        new_list.append(item_ref)\n",
    "    return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(\"\\n|\\t|\\s\\s\", \"\", text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Applatissement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(data):\n",
    "    '''flatten list and dict from depth 1 to depth 0'''\n",
    "    new_data = {}\n",
    "    for key,value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            new_dict = {}\n",
    "            listes = []\n",
    "            if len(value) != 0:\n",
    "                listes.append([key,value[0].keys()])                \n",
    "                for n in listes:\n",
    "                    if len(n[1]) > 0:\n",
    "                        for item in n[1]:\n",
    "                            new_dict[n[0]+\"_\"+item] = []\n",
    "                    \n",
    "                             \n",
    "                for k in new_dict.keys():\n",
    "                    pkey, nkey = k.split(\"_\", 1)                        \n",
    "                    for item in data[pkey]:\n",
    "                        try:\n",
    "                            new_i = item[nkey].encode(\"utf-8\")\n",
    "                        except AttributeError:\n",
    "                            new_i = str(item[nkey]).encode(\"utf-8\")\n",
    "                        new_dict[pkey+\"_\"+nkey].append(new_i)\n",
    "            else:\n",
    "                new_dict[key] = []\n",
    "            \n",
    "            for key, value in new_dict.items():\n",
    "                if isinstance(value,list):\n",
    "                    new_dict[key] = (\"***\").join(value)\n",
    "        \n",
    "            new_data.update(new_dict)\n",
    "        \n",
    "        elif isinstance(value, dict):\n",
    "            for k,v in value.items():\n",
    "                try:\n",
    "                    new_data[key+\"_\"+k] = v.encode(\"utf-8\")\n",
    "                except AttributeError:\n",
    "                    new_data[key+\"_\"+k] = str(v).encode(\"utf-8\")\n",
    "                except UnicodeDecodeError:\n",
    "                    new_data[key+\"_\"+k] = unicode(value.decode(\"utf-8\")).encode(\"utf-8\")\n",
    "        else:\n",
    "            try:\n",
    "                new_data[key] = value.encode(\"utf-8\")\n",
    "            except AttributeError:\n",
    "                new_data[key] = str(value).encode(\"utf-8\")\n",
    "            except UnicodeDecodeError:\n",
    "                new_data[key] = unicode(value.decode(\"utf-8\")).encode(\"utf-8\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse d'un article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'subtitle', u'cat_id', u'updated_at', u'sources', u'arguments_count', u'versions_count', u'votes_total', u'title', u'article_link', u'arguments', u'answer', u'body', u'ranking', u'sources_count', u'votes_ok', u'versions', u'article_id', u'body_anchors', u'created_at', u'author', u'votes_mitige', u'body_links', u'votes_nok']\n"
     ]
    }
   ],
   "source": [
    "# lire le fichier de l'article 9 json\n",
    "data = read_json(\"./article_9.json\")\n",
    "#liste les clé de premiers niveau \n",
    "print [n for n in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travaux de recherche et de statistique\n"
     ]
    }
   ],
   "source": [
    "#decouverte de subtitle\n",
    "print data[\"subtitle\"]\n",
    "#correspond au soustitre de la section (Section 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print data[\"title\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
